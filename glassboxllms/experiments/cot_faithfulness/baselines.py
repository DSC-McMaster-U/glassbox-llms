"""
Pre-computed baseline faithfulness results.

Generated by running CoT faithfulness tests on models via Together AI.
Conditions: 20 samples/dataset, temp 0.7 for CoT, 0.3 for extraction.
"""

from typing import Dict, Any, Optional, List

BASELINES: Dict[str, Dict[str, Dict[str, float]]] = {
    "Gemma-3n-E4B": {
        "arc": {"truncation_faithfulness": 65.0, "error_following": 20.0, "avg_faithfulness": 42.5, "n_samples": 20},
    },
    "Llama-3.1-70B": {
        "arc":  {"truncation_faithfulness": 95.0, "error_following": 40.0, "avg_faithfulness": 67.5, "n_samples": 20},
        "aqua": {"truncation_faithfulness": 85.0, "error_following": 45.0, "avg_faithfulness": 65.0, "n_samples": 20},
        "mmlu": {"truncation_faithfulness": 80.0, "error_following": 35.0, "avg_faithfulness": 57.5, "n_samples": 20},
    },
    "Qwen-3-235B": {
        "arc": {"truncation_faithfulness": 60.0, "error_following": 5.0, "avg_faithfulness": 32.5, "n_samples": 20},
    },
}

MODEL_INFO: Dict[str, Dict[str, Any]] = {
    "Gemma-3n-E4B":  {"full_name": "google/gemma-3n-E4B-it", "size": "4B", "provider": "Google"},
    "Llama-3.1-70B": {"full_name": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo", "size": "70B", "provider": "Meta"},
    "Qwen-3-235B":   {"full_name": "Qwen/Qwen3-235B-A22B-fp8-tput", "size": "235B", "provider": "Alibaba"},
}


def get_baseline(model_name: str, dataset_name: str) -> Optional[Dict[str, float]]:
    """Get baseline results for a model/dataset pair, or None."""
    return BASELINES.get(model_name, {}).get(dataset_name)


def list_baselines() -> Dict[str, List[str]]:
    """Return {model_name: [dataset_names]} for all baselines."""
    return {model: list(ds.keys()) for model, ds in BASELINES.items()}
